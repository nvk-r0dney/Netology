# Домашнее задание к занятию 1. «Введение в виртуализацию. Типы и функции гипервизоров. Обзор рынка вендоров и областей применения»"

### Выполнил студент группы DevOps-25 Шаповалов Кирилл


> 01. Задача 1. Опишите кратко, в чём основное отличие полной (аппаратной) виртуализации, паравиртуализации и виртуализации на основе ОС.

Если кратко - основное и основополагающее отличие всех данных типов виртуализации друг от друга - роль гипервизора, а также использование и распределение ресурсов.

В случае полной (аппаратной) виртуализации - гипервизор берет на себя роль хостовой ОС, тем самым давая возможность гостевым машинам создавать собственные виртуальные устройства, используя железные ресурсы хоста напрямую.

В случае паравиртуализации имеется ОС, на которой отдельно поднимается роль гипервизора, здесь гостевые машины обращаются к физическим ресурсам хоста через API-команды (гипервызовы), также определенное количество ресурсов потребляет сама ОС, на которой поднята роль гипервизора.

В случае виртуализации на основе ОС (контейнеризации) - каждый контейнер, хоть и изолирован от других контейнеров, но использует одно ядро ОС, таким образом, пул ресурсов создается ОС, а гипервизор как таковой - отсутствует.


> 02. Задача 2. Выберите один из вариантов использования организации физических серверов в зависимости от условий использования.

```
Условия:

1. Высоконагруженная база данных, чувствительная к отказу.
2. Различные web-приложения.
3. Windows-системы для использования бухгалтерским отделом.
4. Системы, выполняющие высокопроизводительные расчёты на GPU.
```

```
Варианты организации серверов:

1. Физические сервера.
2. Паравиртуализация.
3. Виртуализация уровня ОС.
```

Если рассматривать идеальную ситуацию, в которой у компании достаточное количество финансово-человеческих средств, то для высоконагруженных баз данных, чувствительных к отказу, предпочтительней использовать физические сервера, где все ресурсы сервера будут отданы только базе данных. Для исключения и минимизации последствий отказа использовать механизмы кластеризации. В ситуациях же, когда вся комания ограничена 4 серверами, а развернуть нужно и то, и это, и еще вон то, широко применяются и технологии виртуализации, включая даже виртуализацию на основе ОС.

В случае веб-приложений важна скорость развертывания, здесь предпочтительней использовать виртуализацию уровня ОС. При правильной организации хранения конфигурационных файлов, а также файлов с данными, иногда намного быстрее переподнять новый контейнер, нежели разбираться что пошло не так со старым. Тем самым увеличивается скорость доставки приложения как до его заказчика, так и до конечного пользователя приложения.

Паравиртуализация - выбор для Windows-систем бухгалтерского отдела. Если же обратиться к материалам лекции - конкретно под Windows можно использовать технологию HyperV от MS, но по жизненному опыту - можно использовать любую, особой разницы нет. Отлично себя показывает и KVM, и oVirt, и даже в VirtualBox все будет прекрасно работать.

С системами, выполняющими сложные расчеты на GPU в настоящее время все далеко неоднозначно. По логике - лучше использовать физические сервера, в которых все мощности как ядер CPU, так и GPU будут целиком отданы приложениям, ведущим эти расчеты. Однако, на сегодняшний день проброс видеокарт прекрасно работает как в VMWare, так и в ProxMox, возможно и где-то еще (с другими продуктами сильно дел не имел). Потому для таких систем можно задействовать и разные варианты виртуализации.


> 03. Задача 3. Выберите подходящую систему управления виртуализацией для предложенного сценария. Детально опишите ваш выбор.


```
Условия:


1. 100 виртуальных машин на базе Linux и Windows, общие задачи, нет особых требований. Преимущественно Windows based-инфраструктура, требуется реализация программных балансировщиков нагрузки, репликации данных и автоматизированного механизма создания резервных копий.
2. Требуется наиболее производительное бесплатное open source-решение для виртуализации небольшой (20-30 серверов) инфраструктуры на базе Linux и Windows виртуальных машин.
3. Необходимо бесплатное, максимально совместимое и производительное решение для виртуализации Windows-инфраструктуры.
4. Необходимо рабочее окружение для тестирования программного продукта на нескольких дистрибутивах Linux.
```

В принципе, так как в 2 из 4 сценириев необходимо использование open source решений, то можно во всех данных случаях использовать KVM. Если использовать его с механизмом управления ProxMox и собственным сервером резервного копирования ProxMox Backup Server - получим полностью автоматизированный процесс создания резервных копий на open source решениях.

В четвертом сценарии необходима виртуализация для linux-дистрибутивов, что также делает оптимальным использование KVM или например VMWare.

В первом сценарии я бы использовал VMWare VSphere, так как на мой взгляд с помощью функции vmotion там замечательно реализованы механизмы репликации, балансировки нагрузки при использовании HA-кластера. А встроенный механизм создания снапшотов позволит иметь некоторое количество точек восстановления. Полноценное же резервное копирование можно осуществить с помощью Veeam B&R, который прекрасно дружит с vCenter и иными продуктами VMWare.


> 04. Задача 4. Опишите возможные проблемы и недостатки гетерогенной среды виртуализации (использования нескольких систем управления виртуализацией одновременно) и что необходимо сделать для минимизации этих рисков и проблем. Если бы у вас был выбор, создавали бы вы гетерогенную среду или нет? Мотивируйте ваш ответ примерами.

Основной проблемой гетерогенной среды виртуализации является конечно же сложность управления и поддержки.

Использование нескольких систем виртуализации повышает расходы, во-первых, на сами данные системы (например, покупка лицензий VMWare вместо использования одних только open source технологий), во-вторых, расходы на персонал, так как поддержка нескольких систем требует либо большей квалификации от одного инженера (а более квалифицированный инженер стоит дороже на рынке труда), либо наличия двух инженеров, специализирующихся на разных системах.

Растет количество точек отказа с принципиально разными возможностями отказа и разными механизмами восстановления, что опять же требует более высокой квалификации от IT-персонала.

Большие компании с высокой доходностью могут себе позволить содержать и большой штат высококвалифицированных IT-специалистов, и для них гетерогенная среда виртуализации - не проблема. Однако, даже в таких компаниях могут решать подобные вопросы стандартизацией. Если корпоративными стандартами установлено использование только open source - то и использоваться там будут только open source технологии (KVM, oVirt например).

В малом и среднем бизнесе, где стремятся сократить расходы на IT направление, я бы точно не стал бы сам и не рекомендовал использовать гетерогенную среду виртуализации.

Единственное исключение - использование контейнеризации совместно с основной виртуализацией на основе какого-либо гипервизора. Ярким примером являются системы мониторинга. Да, можно под каждую составляющую системы мониторинга создать по отдельной виртуальной машине, но что будет в случае отказа одной из машин? Сколько времени уйдет на восстановление? Каков будет процент потерянных данных? Гораздо проще, быстрее, безопасней, а, значит, и разумней использовать под такие цели контейнеризацию.