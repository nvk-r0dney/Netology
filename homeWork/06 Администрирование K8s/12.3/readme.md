# Домашнее задание к занятию «Микросервисы: подходы»

## Выполнил студент группы DevOps-25 Шаповалов Кирилл

<br />

Задача 1 - Обеспечить разработку
--------------------------------

```
Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная 
интеграция и непрерывная поставка. Решение может состоять из одного или нескольких программных 
продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:

- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.
```

Решение
-------

Идеальным и максимально простым решением в данном случае является сочетание `Gitlab + Hashicorp Vault`.

Gitlab обеспечивает весь перечень функционала, описанный в задаче, а Vault позволяет централизованно хранить секреты, при этом замечетально интегрируется в систему Gitlab.

Gitlab может быть как облачным решением, так и установленным локально на инфраструктуре компании. Обладает бесплатной версией или же Enterprice версией, которая дает больше преимуществ, например таких как полнотекстовый поиск по всей системе (может быть весьма полезно при большом количестве проектов и репозиториев), а также улучшенная интеграция с Hashicorp Vault по сравнению с CE-Version.

Gitlab позволяет запускать сборки непосредственно из репозиториев благодаря функционалу Gitlab-CI. Сборки можно осуществить в любой последовательности, а также снабдить различными настройками и параметрами благодаря разным веткам и разным механизмам запуска сборок. Сборки можно запускать только по одной ветке, по всем веткам, по всем кроме какой-либо, по тегу и т.д. Хранение нескольких конфигураций обеспечивается разными ветками внутри репозитория.

Также Gitlab обладает собственным Registry, что позволяет хранить артефакты или готовые Docker-образы, а затем использовать их из своего Registry при сборке и деплое.

Пароли и прочие конфигурационные параметры можно хранить в настройках самого репозитория (Settings->CI-CD->Variables), однако я считаю такой способ не совсем безопасным и верным решением. Лучше использовать Hashicorp Vault для хранения секретов с последующей интеграцией с Gitlab. Для интеграции используется JWT-токен, а на стороне Vault - пользователи, политики и роли.

У Gitlab есть собственные агенты - gitlab-runner - позволяющие запускать сборки на собственных серверах и обладающие обширным механизмом реализации этих самых сборок (можно в Docker, можно используя shell и т.д.).

Если рассматривать другие продукты - Jenkins не обладает таким набором функционала и его придется расширять плагинами и доп. интеграциями, а TeamCity может показаться слишком сложным и, на мой взгляд, достаточно специфичный продукт из пространства Atlassian.

<br />

Задача 2 - Логи
---------------

```
Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и 
принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:

- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.
```

Решение
-------

Решение будет достаточно распространенным и известным :)

ELK-стек, с одной лишь разницей Logstash я бы заменил на Vector, мне больше понравился этот продукт. Он менее затратен к ресурсам при преобразовании логов, обладает широким набором как точек входа логов, так и конечных точек отправки логов. К тому же он позволяет создать распределенную систему, в которой Vector на хостах будет отправлять логи в агрегирующий Vector, а он уже будет писать данные в ElasticSearch.

ElasticSearch так же позволяет создать распределенное решение с репликацией данных и реализацией краткосрочного и долгосрочного хранения данных.

Пользовательский интерфейс Kibana позволяет осуществлять поиск с использованием фильтрации по логам, а также можно предоставить разработчикам доступ с использованием доменной авторизации для отслеживания логов своих приложений.

Решение полностью удовлетворяет всем перечисленным в задаче условиям.

<br />

Задача 3 - Мониторинг
---------------------

```
Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и 
принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:

- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.
```

Решение
-------

Начнем с конца - пользовательский интерфейс. Тут выбор за Grafana. Отличное решение, также обладающее платной и бесплатной версиями. Широкий функционал, большое количество поддерживаемых источников данных, возможность агрегировать информацию, строить запросы, настраивать различные панели и дашборды, а также встроенный механизм управления алертами однозначно делает это решение лидером в сфере пользовательских интерфейсов в мониторинге.

Далее, что касается сбора метрик с микросервисов - тут решением скорей всего будет являться Prometheus-стек: Prometheus, Exporters, Alertmanager. Обладает широким функионалом, возможностью сбора метрик с совершенно разных источников благодаря Exporter'ам, а Alertmanager предоставляет возможность создавать алерты и управлять ими. Функционал можно расширять за счет написания кастомных экспортеров для метрик конкретных приложений.

Однако, среди широкого круга админов и причастных к ним бытует мнение, что Prometheus не очень адекватно работает с большим количеством метрик в единицу времени (сам достоверно сказать не могу, не было возможности настолько загрузить Prometheus, чтоб проерить это), а потому наверное я бы разбил Prometheus на несколько инстансов согласно сферам мониторинга (ну например, Докеру - свой, Куберу - свой, Вебу - свой и т.д.), а метрики из них отправлял бы в VictoriaMetrics, которая, в свою очередь, уже отдавала бы их в Grafana.

Там, где нужно очень быстрое получение метрик специалистами - использовал бы InfluxDB+Telegraf. Этот стек позволяет оперативно реагировать на изменения в критически важных сервисах, где даже 10 секунд простоя влекут потери, убытки и т.д. На личном опыте могу сказать - решение отлично работает с мониторингом виртуализации (VMWare, ProxMox), 1C, MSSQL Server и т.д. Единственный нюанс - алертинг я бы отдал на откуп Grafana, потому что на мой взгляд в самом InfluxDB как-то кривовато реализована отправка алертов например в Telegram - самый распространенный ныне способ оповещения (не исключаю, что так было конкретно с той версией, которую довелось настраивать мне).