# Домашнее задание к занятию 6. «Troubleshooting»

### Выполнил студент группы DevOps-25 Шаповалов Кирилл

> <b>Задача 1. Troubleshooting MongoDB</b>

Условие задачи:

    Перед выполнением задания ознакомьтесь с документацией по администрированию MongoDB.
    Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты 
    происходит CRUD-операция в MongoDB и её нужно прервать.
    Вы как инженер поддержки решили произвести эту операцию:
     - напишите список операций, которые вы будете производить для остановки запроса пользователя;
     - предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.

Основными командами в данном случае (как сказано в документации к Монге) будут являться:

* db.currentOp()
* db.killOp(`<opID>`)

Последовательность применения будет такая:

1. Сначала определяем ID операции, которая длится дольше 3 минут:

```
db.currentOp(
    {
        "active" : true,
        "secs_running" : { "$gt" : 180 }
    }
)
```
2. Получив ID операции - завершаем ее командой db.killOp(`<opID>`).

Для оптимизации запросов в MongoDB можно сделать следующее:

1. Построить индексы (описано здесь <a href="https://mongodb.com/docs/manual/core/query-optimization/">https://mongodb.com/docs/manual/core/query-optimization/</a>)
2. Использовать оптимальный код в запросах, например, правильно задавать лимиты и сортировки (описано там же по ссылке выше)
3. Для операций записи или изменения - оптимально хранить БД на твердотельных накопителях, это ускорит работу с запросами к базе как минимум в несколько раз (описано здесь <a href="https://mongodb.com/docs/manual/core/write-perfomance/">https://mongodb.com/docs/manual/core/write-perfomance/</a>)
4. В крайнем случае задать ограничение на выполнение CRUD операций через `maxTimeMS` (описано здесь <a href="https://mongodb.com/docs/manual/reference/method/cursor.maxTimeMS/">https://mongodb.com/docs/manual/reference/method/cursor.maxTimeMS/</a>)

> <b>Задача 2. Troubleshooting Redis</b>

Условие задачи:

    Вы запустили инстанс Redis для использования совместно с сервисом,
    который использует механизм TTL. Причём отношение количества записанных 
    key-value-значений к количеству истёкших значений есть величина постоянная 
    и увеличивается пропорционально количеству реплик сервиса.

    При масштабировании сервиса до N реплик вы увидели, что:

        - сначала происходит рост отношения записанных значений к истекшим,
        - Redis блокирует операции записи.

    Как вы думаете, в чём может быть проблема?

Я пока имею очень малый опыт в общении с Redis'ом, а на практике так вообще пока его не использовал, потому могу оперировать только тем, что описано в документации. 

В первую очередь, всегда помним: Redis - однопоточное приложение!

Блок "Latency generated by expires" в документации к Redis'у говорит о том, что Redis начинает блокировать операции записи как только количество истекающих в одно и то же время ключей начинает превышать 25% от общего набора выбранных ключей. 

Также, к проблеме с блокировкой может привести закончившаяся память. Redis у нас установлен на некоторую операционную систему, где помимо него есть и еще какие-либо приложения, сами процессы операционной системы и т.д. Возможно и такое, что возросшая нагрузка на машину привела к тому, что объем оперативной памяти подошел к концу.

В любом случае, важно иметь под рукой систему мониторинга, которая своевременно покажет, где проблема, что позволит и своевременно на нее отреагировать.

> <b>Задача 3. Troubleshooting MySQL</b>

Условие задачи:

    Вы подняли базу данных MySQL для использования в гис-системе. 
    При росте количества записей в таблицах базы пользователи начали жаловаться 
    на ошибки вида:

    InterfaceError: (InterfaceError) 2013: 
    Lost connection to MySQL server during query u'SELECT..... '

    Как вы думаете, почему это начало происходить и как локализовать проблему?

    Какие пути решения этой проблемы вы можете предложить?

В первую очередь необходимо понять - доступен ли инстанс MySQL, ситуация может быть банальна - сетевой сбой и инстанс просто недоступен.

Если сетевая проблема исключена, далее смотрим - запущен ли демон mysql. Нет ли какой-то причины, по которой демон может циклично перезапускаться. В этом нам помогут логи демона mysql, также можно обратиться к чтению журнала `journalctl -xe | grep mysql`.

Если же сетевой проблемы нет, демон mysql запущен и стабильно работает - нужно разбираться с настройками инстанса.

1. Можно изменить параметры `connect_timeout` и `net_read_timeout`, по умолчанию эти параметры равны 10 и 30 секунд, то есть MySQL будет ждать 10 секунд, прежде чем ответить ошибкой таймаута соединения, если поставить значение например 300 секунд - это, возможно, решит проблему.

2. Можно изменить параметр `max_allowed_packet` - если вдруг сервер mysql получает пакет больше, чем задано в данном параметре, он завершает соединение с ошибкой. Нужно повысить значение данного параметра и посмотреть, что будет дальше.

3. Ну и наконец настраиваем и смотрим лог SLOW QUERY, чтобы понять что за запрос приходит в момент ошибки, возможно, этот анализ выявит неоптимальные параметры в запросе, что позволит оптимизировать запрос и устранить ошибку.

> <b>Задача 4. Troubleshooting PostgreSQL</b>

Условие задачи:

    Вы решили перевести гис-систему из задачи 3 на PostgreSQL, 
    так как прочитали в документации, что эта СУБД работает с большим 
    объёмом данных лучше, чем MySQL.

    После запуска пользователи начали жаловаться, что СУБД время от времени 
    становится недоступной. В dmesg вы видите, что:

    postmaster invoked oom-killer

    Как вы думаете, что происходит?

    Как бы вы решили эту проблему?

OOM-killer - тот самый замечательный пушистый зверек, который приходит, когда на сервере начинает не хватать ресурсов или когда Postgres съедает всю память сервера (OOM - Out Of Memory).

1. Возможно, наступил тот самый момент, когда нагрузка на сервер переросла его ресурсы и нужно их увеличить.

2. Не использовать там, где стоит PostgreSQL, других приложений, активно использующих память.

3. Задать ограничение по потребляемой памяти для PostgreSQL.